{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Hierarchical Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"samples2.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "#we are plotting the points in 2 dimensions just to give you an idea of their positions in the space\n",
    "#BUT those are just 2 out of the 3 (X,Y,Z) original dimensions \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df.iloc[:,0], df.iloc[:,1])\n",
    "\n",
    "labels=[\"ID0\",\"ID1\",\"ID2\",\"ID3\",\"ID4\"]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    ax.annotate(labels[i], (df.iloc[i,0], df.iloc[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering using SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "labels = df.index.values #how to get the data frame index as an array\n",
    "row_dist = pd.DataFrame(squareform(pdist(df,metric='euclidean')),columns=labels,index=labels)\n",
    "row_dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix of Distances between all pairs of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the complete linkage to agglomerate the observations\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "row_clusters = linkage(df.values, method='complete', metric='euclidean')\n",
    "row_clusters\n",
    "\n",
    "#  method\n",
    "#     - ward minimizes the variance of the clusters being merged.\n",
    "#     - average uses the average of the distances of each observation of the two sets.\n",
    "#     - complete or maximum linkage uses the maximum distances between all observations of the two sets.\n",
    "#     - single uses the minimum of the distances between all observations of the two sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_clusters = pd.DataFrame(row_clusters, columns =['row label 1', 'row label 2', 'distance', 'n of items in each clust'])\n",
    "row_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix of linkages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_clusters.iloc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In its first iteration the linkage algorithm decided to merge the two clusters (original samples here) \n",
    "with indices 0 and 4, as they had a distance of 3.83539555. \n",
    "\n",
    "This created a cluster with a total of 2 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_clusters.iloc[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second iteration the algorithm decided to merge the clusters (original samples here as well) \n",
    "with indices 1 and 2, which had a distance of 4.34707339. \n",
    "\n",
    "This again formed another cluster with a total of 2 samples.\n",
    "\n",
    "The indices of the clusters until now correspond to our samples. \n",
    "Remember that we had a total of 5 samples, so indices 0 to 4. \n",
    "\n",
    "Let's have a look at the rest of iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that until iteration 1 the algorithm only directly merged original samples. \n",
    "We can also observe the monotonic increase of the distance.\n",
    "\n",
    "\n",
    "In iteration 2 the algorithm decided to merge the original sample 3 with cluster index 5. \n",
    "If you paid attention the 5 should astonish you as we only have original sample indices 0 to 4 for our 5 samples. \n",
    "All indices idx >= len(X) actually refer to the cluster formed in row_clusters[idx - len(X)].\n",
    "\n",
    "This means that while idx 4 corresponds to X[4] that idx 5 corresponds to the cluster formed in row_clusters[0],idx 6 to row_clusters[1], 7 to row_clusters[2], ...\n",
    "\n",
    "Hence, the merge iteration 2 merged sample 3 to our samples 0 and 4 that were previously merged in iteration 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(df.iloc[:,0], df.iloc[:,1])\n",
    "#we are plotting the points in 2 dimensions just to give you an idea of their positions in the space\n",
    "#BUT those are just 2 out of the 3 (X,Y,Z) original dimensions \n",
    "\n",
    "plt.scatter(df.iloc[0,0], df.iloc[0,1], c='red')#plot a red id0\n",
    "plt.scatter(df.iloc[3,0], df.iloc[3,1], c='green')#plot a green id3\n",
    "plt.scatter(df.iloc[4,0], df.iloc[4,1], c='yellow')#plot a yellow id4\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the corresponding dendrogram\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "row_dendr = dendrogram(row_clusters, labels = labels)\n",
    "plt.ylabel('Euclidean Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.read_csv(\"sample1.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the corresponding dendrogram\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "dend = dendrogram(linkage(X, method='ward'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# n_clustersint The number of clusters \n",
    "# affinitystring:  “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”.\n",
    "#     If linkage is “ward”, only “euclidean” is accepted. If “precomputed”, a distance matrix is needed \n",
    "#\n",
    "#     - ward minimizes the variance of the clusters being merged.\n",
    "#     - average uses the average of the distances of each observation of the two sets.\n",
    "#     - complete or maximum linkage uses the maximum distances between all observations of the two sets.\n",
    "#     - single uses the minimum of the distances between all observations of the two sets.\n",
    "\n",
    "\n",
    "set=X\n",
    "\n",
    "for linkage in ('ward', 'average', 'complete', 'single'):\n",
    "    clustering = AgglomerativeClustering(linkage=linkage, n_clusters=3)\n",
    "    clustering.fit(set)\n",
    "\n",
    "    plt.scatter(set[0], set[1], c=clustering.labels_)\n",
    "    plt.title(linkage)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X2 = pd.read_csv(\"sample2.csv\", header=None)\n",
    "\n",
    "set= X2.iloc[:,0:2]\n",
    "\n",
    "for linkage in ('ward', 'average', 'complete', 'single'):\n",
    "    clustering = AgglomerativeClustering(linkage=linkage, n_clusters=3)\n",
    "    clustering.fit(set)\n",
    "\n",
    "    plt.scatter(set[0], set[1], c=clustering.labels_)\n",
    "    plt.title(linkage)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Anisotropicly distributed data\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "# transformation=PDP^-1 D=diag(1.2,0,2) and P=[[0.07107, -0.83205], [-0.707107, -0.5547]]\n",
    "# the transformation expands in the direction [0.710,-0.707] and shrinks in the direction  [-0.832, -0.5547]\n",
    "\n",
    "X3 = pd.DataFrame(np.dot(X, transformation))\n",
    "\n",
    "set=X3\n",
    "\n",
    "for linkage in ('ward', 'average', 'complete', 'single'):\n",
    "    clustering = AgglomerativeClustering(linkage=linkage, n_clusters=3)\n",
    "    clustering.fit(set)\n",
    "\n",
    "    plt.scatter(set[0], set[1], c=clustering.labels_)\n",
    "    plt.title(linkage)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X4 = pd.read_csv(\"sample4.csv\", header=None)\n",
    "\n",
    "set= X4\n",
    "for linkage in ('ward', 'average', 'complete', 'single'):\n",
    "    clustering = AgglomerativeClustering(linkage=linkage, n_clusters=2)\n",
    "    clustering.fit(set)\n",
    "\n",
    "    plt.scatter(set[0], set[1], c=clustering.labels_)\n",
    "    plt.title(linkage)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
