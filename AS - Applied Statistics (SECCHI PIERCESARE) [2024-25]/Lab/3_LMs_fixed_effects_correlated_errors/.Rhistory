rm(list=ls())
library(settings)
install.packages("settings")
rm(list=ls())
library(settings)
reset(options)
graphics.off()
library(nlmeU)  # --> for the dataset
install.packages("nlmeU")
rm(list=ls())
library(settings)
reset(options)
graphics.off()
library(nlmeU)  # --> for the dataset
library(nlme)   # --> for models implementation
library(lattice)
library(corrplot)
install.packages("corrplot")
rm(list=ls())
library(settings)
reset(options)
graphics.off()
library(nlmeU)  # --> for the dataset
library(nlme)   # --> for models implementation
library(lattice)
library(corrplot)
library(plot.matrix)
install.packages("plot.matrix")
rm(list=ls())
library(settings)
reset(options)
graphics.off()
library(nlmeU)  # --> for the dataset
library(nlme)   # --> for models implementation
library(lattice)
library(corrplot)
library(plot.matrix)
data(armd.wide) # --> wide format
head(armd.wide) # lesion and line0 contain additional information, which we won't use
help(armd.wide)
dim(armd.wide)
str(armd.wide)
data(armd0)     # --> long (or longitudinal) format
head(armd0)     # new features: time.f, time, tp, and visual
help(armd0)
dim(armd0)
str(armd0)
data(armd)      # --> long (or longitudinal) format (subset of armd0, without baseline)
head(armd)
help(armd)
dim(armd)
str(armd)
# armd was built from armd0 as follows:
auxDt <- subset(armd0, time > 0)          # Post-baseline measures
dim(auxDt)                                # No. of rows & cols
levels(auxDt$time.f)                      # Levels of treat.f
armd <- droplevels(auxDt)                 # Drop unused levels
levels(armd$time.f)                       # Baseline level dropped
armd <- within(armd, {                    # Contrasts assigned for dealing with ORDERED factors
contrasts(time.f) <- contr.poly(4, scores = c(4, 12, 24, 52)) # we are changing scores
# If you are interested in further details, see 1.5.1 in 1_5_Supplementary.R
})
armd0.subset <- subset(armd0, as.numeric(subject) %in% seq(1, 240, 5)) # 1 every 5 patients
xy1 <- xyplot(visual ~ time | treat.f,
# visual and time are plotted against each other in separate
# panels for different values of 'treat.f' factor.
groups = subject,
data = armd0.subset,
type = "l", lty = 1)
xy1 <- xyplot(visual ~ time | treat.f,
# visual and time are plotted against each other in separate
# panels for different values of 'treat.f' factor.
groups = subject,
data = armd0.subset,
type = "l", lty = 1)
update(xy1, xlab = "Time (in weeks)",
ylab = "Visual acuity",
grid = "h")
# Comments:
rm(list=ls())         # Clear all objects from the workspace
library(settings)     # Load the 'settings' package
reset(options)        # Reset all global options to their default values
graphics.off()
library(nlmeU)  # --> for the dataset
library(nlme)   # --> for models implementation
library(lattice)
library(corrplot)
library(plot.matrix)
data(armd.wide) # --> wide format
head(armd.wide) # lesion and line0 contain additional information, which we won't use
help(armd.wide)
str(armd.wide)         # Display the structure of 'armd.wide', showing data types of each column
data(armd0)     # --> long (or longitudinal) format
head(armd0)     # new features: time.f, time, tp, and visual
help(armd0)
dim(armd0)
str(armd0)
data(armd)      # --> long (or longitudinal) format (subset of armd0, without baseline)
head(armd)
help(armd)
dim(armd)
str(armd)
auxDt <- subset(armd0, time > 0)        # Create a new dataset 'auxDt' by selecting rows where 'time' is greater than 0 (post-baseline data)
dim(auxDt)                             # Get the dimensions (number of rows and columns) of 'auxDt'
levels(auxDt$time.f)                   # Show the levels of the factor variable 'time.f' in the dataset 'auxDt'
View(auxDt)
levels(auxDt$time.f)                      # Levels of treat.f
armd <- droplevels(auxDt)                 # Drop unused levels
levels(armd$time.f)                       # Baseline level dropped
View(armd)
armd <- within(armd, {                    # Contrasts assigned for dealing with ORDERED factors
contrasts(time.f) <- contr.poly(4, scores = c(4, 12, 24, 52)) # we are changing scores
# If you are interested in further details, see 1.5.1 in 1_5_Supplementary.R
})
armd0.subset <- subset(armd0, as.numeric(subject) %in% seq(1, 240, 5)) # 1 every 5 patients
xy1 <- xyplot(visual ~ time | treat.f,
# visual and time are plotted against each other in separate
# panels for different values of 'treat.f' factor.
groups = subject,
data = armd0.subset,
type = "l", lty = 1)
xy1 <- xyplot(visual ~ time | treat.f,
# visual and time are plotted against each other in separate
# panels for different values of 'treat.f' factor.
groups = subject,
data = armd0.subset,
type = "l", lty = 1)
update(xy1, xlab = "Time (in weeks)",
ylab = "Visual acuity",
grid = "h")
xy1 <- xyplot(visual ~ time | treat.f,
# visual and time are plotted against each other in separate
# panels for different values of 'treat.f' factor.
groups = subject,
data = armd0.subset,
type = "l", lty = 1)
update(xy1, xlab = "Time (in weeks)",
ylab = "Visual acuity",
grid = "h")
xy1 <- xyplot(visual ~ time | treat.f,
# visual and time are plotted against each other in separate
# panels for different values of 'treat.f' factor.
groups = subject,
data = armd0.subset,
type = "l", lty = 1)
update(xy1, xlab = "Time (in weeks)",
ylab = "Visual acuity",
grid = "h")
# The factor miss.pat that indicates which of the four
# post-randomization measurements are missing for a particular patient
table(armd.wide$miss.pat)
# sample means across time and treatment
flst <- list(armd0$time.f, armd0$treat.f)                                     # "By" factors
(tN <-  tapply(armd0$visual, flst, FUN = function(x) length(x[!is.na(x)])))   # Counts
tMn <- tapply(armd0$visual, flst, FUN = mean)     # Sample means
tMd <- tapply(armd0$visual, flst, FUN = median)   # Sample medians
colnames(res  <- cbind(tN, tMn, tMd))             # Column names
nms1 <- rep(c("P", "A"), 3)
nms2 <- rep(c("n", "Mean", "Median"), rep(2, 3))
colnames(res) <- paste(nms1, nms2, sep = ":")     # New column names
res
bw1 <- bwplot(visual ~ time.f | treat.f, data = armd0)  # bwplot from package lattice
xlims <- c("Base", "4\nwks", "12\nwks", "24\nwks", "52\nwks")
update(bw1, xlim = xlims, pch = "|")
# measurements for complete cases only (n = 188)
visual.x <- subset(armd.wide, select = c(visual0:visual52))
(varx <- var(visual.x, use = "complete.obs"))            # Var-cov matrix
plot(varx, col=colorRampPalette(c("blue", "white", "red")))
# increase of the variance of visual acuity measurements obtained at later timepoints.
diag(varx)                                               # Var-cov diagonal elements
print(cor(visual.x, use = "complete.obs"), digits = 2)   # Corr matrix
cov2cor(varx)                                            # Corr matrix (alternative way)
plot(cov2cor(varx), col=colorRampPalette(c("blue", "white", "red")))
#______________________________________________________________________________#
##### 1.1.3 ARMD Trial: Linear Model with Homogeneous Variance (Chapter 6) #####
#______________________________________________________________________________#
data(armd, package = "nlmeU")
data(armd, package = "nlmeU")
lm1.form <- formula(visual ~ -1 + visual0 + time.f + treat.f:time.f )
# we now fit the linear model
lm6.1 <- lm(lm1.form, data = armd)         # through lm()
lm6.1
summ <- summary(lm6.1)                     # Summary
summ
# Annual abundances of three bird species measured at three islands in Hawaii from 1956 to 2003.
setwd("/Users/amirh_jandaghian/Documents/Polimi/Y 02/Polimi - Git/AS - Applied Statistics (SECCHI PIERCESARE) [2024-25]/Lab/3_LMs_fixed_effects_correlated_errors")
# We focus on Moorhen.Kauai:
Hawaii = read.table('Hawaii.txt', header=T)
Hawaii$Birds <- sqrt(Hawaii$Moorhen.Kauai)
plot(Hawaii$Year, Hawaii$Moorhen.Kauai, xlab = "Year", ylab = "Moorhen abundance on Kauai")
library(nlme)
lm0 = gls(Moorhen.Kauai ~ Rainfall + Year, na.action = na.omit, data = Hawaii)
summary(lm0)
plot(lm0) # Pearson residuals are plotted
# we try to stabilize it by applying a square root transformation
lm1 = gls(sqrt(Moorhen.Kauai) ~ Rainfall + Year, na.action = na.omit, data = Hawaii)
plot(Hawaii$Year, sqrt(Hawaii$Moorhen.Kauai), xlab = "Year", ylab = "Moorhen abundance on Kauai")
plot(lm1)
# or with the logarithm
lm2 = gls(log(Moorhen.Kauai) ~ Rainfall + Year, na.action = na.omit, data = Hawaii)
plot(Hawaii$Year, log(Hawaii$Moorhen.Kauai), xlab = "Year", ylab = "Moorhen abundance on Kauai")
plot(lm2)
plot(Hawaii$Year, log(Hawaii$Moorhen.Kauai), xlab = "Year", ylab = "Moorhen abundance on Kauai")
plot(lm2)
Hawaii$Birds <- sqrt(Hawaii$Moorhen.Kauai)
M0 <- gls(Birds ~ Rainfall + Year, na.action = na.omit, data = Hawaii)
summary(M0)
# To detect patterns:
# --> standardized residuals
plot(M0)
# --> auto-correlation function (ACF)
# The value of the ACF at different time lags gives an indication whether there is any auto-correlation in the data
E <- residuals(M0, type = "normalized")
I1 <- !is.na(Hawaii$Birds)
Efull <- vector(length = length(Hawaii$Birds))
Efull <- NA
Efull[I1] <- E   # we insert the missing values that were removed by gls with na.omit
acf(Efull, na.action = na.pass, main = "Auto-correlation plot for residuals")
M1 <- gls(Birds ~ Rainfall + Year,
na.action = na.omit, data = Hawaii ,
correlation = corCompSymm(form =~Year))
summary(M1)
anova(M0, M1) # --> no improvements
M2 <- gls(Birds ~ Rainfall + Year,
na.action = na.omit, data = Hawaii,
correlation = corAR1(form =~ Year))
summary(M2)
anova(M0,M2)  # --> improvement
# 3) ARMA Error Structures
# ARMA model has two parameters defining its order:
# the number of auto-regressive parameters (p)
# and the number of moving average parameters (q)
# if p=1 and q=0 we have AR-1 model
# in general, better not to select a model with p,q > 2 or 3 (convergence problems)
cs1 <- corARMA(c(0.2), p = 1, q = 0) # we provide arbitrary starting points
cs2 <- corARMA(c(0.3, -0.3), p = 2, q = 0)
M3arma1 <-gls(Birds ~ Rainfall + Year,
na.action = na.omit,
correlation = cs1, data = Hawaii)
M3arma2 <- gls(Birds ~ Rainfall + Year,
na.action = na.omit,
correlation = cs2, data = Hawaii)
AIC(M0, M2, M3arma1, M3arma2)
summary(M3arma2)
# Phi1 close to 1 may indicate a more serious problem of the residuals
# Phi1 close to 1 may indicate a more serious problem of the residuals
# being non-stationary (non-constant mean or variance).
# Phi1 close to 1 may indicate a more serious problem of the residuals
# being non-stationary (non-constant mean or variance).
# Note that the auto-correlation function in the plot becomes positive again for
# Phi1 close to 1 may indicate a more serious problem of the residuals
# being non-stationary (non-constant mean or variance).
# Note that the auto-correlation function in the plot becomes positive again for
# larger time lags, suggesting that an error structure that allows for a sinusoidal
# NB: "there is not much to be gained from finding the perfect correlation structure
# NB: "there is not much to be gained from finding the perfect correlation structure
# compared to finding one that is adequate".
# NB: "there is not much to be gained from finding the perfect correlation structure
# compared to finding one that is adequate".
# [Schabenberger and Pierce (2002), Diggle et al. (2002), andVerbeke and Molenberghs (2000)]
# NB: "there is not much to be gained from finding the perfect correlation structure
# compared to finding one that is adequate".
# [Schabenberger and Pierce (2002), Diggle et al. (2002), andVerbeke and Molenberghs (2000)]
# NB: "there is not much to be gained from finding the perfect correlation structure
# compared to finding one that is adequate".
# [Schabenberger and Pierce (2002), Diggle et al. (2002), andVerbeke and Molenberghs (2000)]
# NB: "there is not much to be gained from finding the perfect correlation structure
# compared to finding one that is adequate".
# [Schabenberger and Pierce (2002), Diggle et al. (2002), andVerbeke and Molenberghs (2000)]
