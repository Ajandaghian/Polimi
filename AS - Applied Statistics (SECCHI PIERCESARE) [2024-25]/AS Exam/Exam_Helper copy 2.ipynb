{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rm(list = ls())         # Remove all objects from the workspace\n",
    "graphics.off()          # Close all open graphics devices\n",
    "\n",
    "# Load required libraries\n",
    "library(settings)       # For resetting global options\n",
    "reset(options)          # Reset all global options to default values\n",
    "\n",
    "library(nlmeU)          # For datasets\n",
    "library(nlme)           # For model implementation\n",
    "library(lattice)        # For lattice plotting\n",
    "library(corrplot)       # For correlation matrix visualization\n",
    "library(plot.matrix)    # For matrix plots\n",
    "library(MASS)           # For statistical functions\n",
    "library(car)            # For regression diagnostics\n",
    "library(lme4)           # For mixed-effects models\n",
    "library(insight)        # For model insight extraction\n",
    "library(rgeoda)         # For geospatial analysis\n",
    "library(sf)             # For handling spatial data\n",
    "library(sp)             # For spatial data management\n",
    "library(gstat)          # For geostatistical analysis\n",
    "library(geoR)           # For geostatistical modeling\n",
    "library(geojsonio)\n",
    "library(KFAS)\n",
    "library(HMM)\n",
    "\n",
    "set.seed(????)\n",
    "\n",
    "# Set working directory\n",
    "setwd(\"/Users/amirh_jandaghian/Documents/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data  <- read.table('data.text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "####### Visualization #######\n",
    "\n",
    "### line chart for each section\n",
    "xy1 <- xyplot(Y ~ X | section.f,\n",
    "    # visual and time are plotted against each other in separate\n",
    "    # panels for different values of 'treat.f' factor.\n",
    "    groups = grouping_col,\n",
    "    data = data,\n",
    "    type = \"l\",\n",
    "    lty = 1\n",
    ")\n",
    "\n",
    "### boxplot for each section\n",
    "bw1 <- bwplot(y ~ x.f | sectuib.f, data = data)  # bwplot from package lattice\n",
    "    #xlims <- c(\"Base\", \"4\\nwks\", \"12\\nwks\", \"24\\nwks\", \"52\\nwks\")\n",
    "    #update(bw1, xlim = xlims, pch = \"|\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#### Fitting and Results - homo\n",
    "\n",
    "#(GLS)\n",
    "lm1.form <- visual ~ -1 + visual0 + time.f + treat.f:time.f   # model defined last time\n",
    "fm6.1 <- gls(lm1.form, data = armd)\n",
    "summary(fm6.1)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------#---------------------------------------------------------------------------------\n",
    "# MODEL FORMULATION in R: (LM)\n",
    "form.form <- formula(   visual ~ -1 + visual0 + time.f + treat.f:time.f    ) #forms on the 1.2 file\n",
    "# we now fit the linear model\n",
    "lm_fit <- lm(    form.form, data = armd   )  \n",
    "\n",
    "sum = summary(lm_fit) \n",
    "summary(lm_fit) \n",
    "\n",
    "### GLS fitting in the file 1.1 \n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# How to obtain information from our lm\n",
    "lm_fit$coefficients       # the betas\n",
    "#lm_fit$residuals          # ^epsilon\n",
    "#lm_fit$fitted.values      # ^y\n",
    "lm_fit$rank               # rank\n",
    "lm_fit$df.residual        # degrees of freedom of the model (n-rank)\n",
    "#lm_fit$model              # the dataframe\n",
    "#rstandard(lm_fit)         # the standardized residuals\n",
    "summ$sigma               # sigma (estimate of the residual standard deviation)\n",
    "\n",
    "vcov(lm_fit)              # variance-covariance matrix\n",
    "sqrt(diag(vcov(lm_fit)))  # standard errors of the coefficients\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Confidence intervals for the coefficients\n",
    "alpha = 0.05\n",
    "confint(lm_fit,level = 1 - alpha)\n",
    "\n",
    "# We can correct them through Bonferroni\n",
    "confint(lm_fit,level = 1 - alpha/length(lm_fit$coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### Predicting\n",
    "\n",
    "# Step 1: we generate new observations - 3 patients (within the range of the observed values)\n",
    "X.new <- data.frame(time.f = ordered(rep(c('4wks', '12wks', '24wks', '52wks' ),3)),\n",
    "                visual0 = c(rep(50,4), rep(60,4), rep(55,4)),\n",
    "                treat.f = factor(c(rep('Active',4), rep('Placebo',4), rep('Active',4)))\n",
    ")\n",
    "\n",
    "X.new <- data.frame(colname1 = c(11,11,11)^2, name2=c(1,0,0), name3=c(0,1,0))\n",
    "\n",
    "X.new\n",
    "\n",
    "# Step 2: we build the intervals (for each single observation)\n",
    "IC <-predict(lm_fit, X.new, interval=\"confidence\", level=0.95)\n",
    "IC \n",
    "\n",
    "IP <-predict(lm_fit, X.new, interval=\"prediction\", level=0.95)\n",
    "IP \n",
    "\n",
    "#?predict.lm # look at the plot in the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### Evaluating the model\n",
    "\n",
    "anova(lm6.1_2, lm6.1)                         # fm6.1_2 nested in fm6.1\n",
    "# We look at the AIC because the models are non-nested and LR test cannot be performed\n",
    "\n",
    "AIC(lm6.1_2, lm6.1)                           # AIC of the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#### Diagnostics plots\n",
    "par(bg = \"white\") # Sets the background color to white\n",
    "\n",
    "# Automatic diagnostic plots (graphically)\n",
    "#x11()\n",
    "par(mfrow = c(1,1))\n",
    "plot(lm_fit) #resid vs fitted values \n",
    "\n",
    "shapiro.test(lm_fit$residuals) # problem confirmed by shapiro.test\n",
    "#If the p-value is small (typically < 0.05), it suggests the residuals are NOT normally distributed.\n",
    "\n",
    "plot(lm_fit$residuals) # resid vs index\n",
    "abline(h=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# color - let's color the residuals relative to different columns\n",
    "x = data$column\n",
    "par(bg = \"white\") # Sets the background color to white\n",
    "colori = rainbow(length(unique(x))) # Creates a color palette for each unique value in 'x'\n",
    "num_sub = table(x) # Gets the frequency of each subject\n",
    "colori2 = rep(colori, num_sub) # Replicates the colors based on frequency\n",
    "plot(lm_fit$residuals, col=colori2) # Plots residuals with respective colors\n",
    "abline(h=0) # Adds a horizontal line at y=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# boxplot of residuals\n",
    "x = data$column.f\n",
    "boxplot(lm_fit$residuals ~ x, col=colori,\n",
    "        xlab='Time.f', ylab='Residuals') # --> informative\n",
    "# -> the variance of the observations increases in time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#GLS models lab2\n",
    "plot(fm9.2, resid(., type = \"response\") ~ time)       # Raw residuals vs time \n",
    "bwplot(resid(fm9.2, type='response') ~ time.f,        # Raw residuals vs time.f\n",
    "        pch = \"|\", data = armd)      \n",
    "\n",
    "# Pearson residuals [ ^eps_i/sqrt(Var(y_i)) ]\n",
    "plot(fm9.2, resid(., type = \"pearson\" ) ~ fitted(.)) # Pearson vs fitted\n",
    "plot(fm9.2, resid(., type = \"pearson\") ~ time)       # Pearson vs time \n",
    "bwplot(resid(fm9.2, type = \"pearson\") ~ time.f,pch = \"|\", data = armd)     # Pearson vs time.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#### Fitting and Results -  independent, heteroscedastic residual errors \n",
    "\n",
    "#_varClass___________parameters___________________Group #########################################\n",
    "# varFixed()         value                        known weights\n",
    "# varIdent()         value, form, fixed           <delta>-group\n",
    "# varExp()           value, form, fixed           <delta>-group, <delta,mu>-group, <mu>-group\n",
    "# varPower()         value, form, fixed           <delta>-group, <delta,mu>-group, <mu>-group\n",
    "# varConstPower()    const, power, form, fixed    <delta>-group, <delta,mu>-group, <mu>-group\n",
    "\n",
    "\n",
    "###### model 9.0: lambda_i are known, i.e. lambda(v) ######\n",
    "fm9.0 <- gls(visual ~ -1 + visual0 + time.f + treat.f:time.f, \n",
    "             method = 'REML',                   # default\n",
    "             weights = varFixed(value = ~time), # Var.function; lambda_i(v_i) (v_i is known and observable)\n",
    "             data = armd)\n",
    "\n",
    "\n",
    "###### model 9.1: <delta>-group i.e. lambda(delta,v) ######\n",
    "fm9.1 <- gls(visual ~ -1 + visual0 + time.f + treat.f:time.f,                  \n",
    "         weights = varIdent(form = ~ 1|time.f), # Var.function; <delta>-group i.e. lambda(delta,v)\n",
    "                    # delta_1 = 1\n",
    "                    # delta_2 = sigma_2/sigma_1\n",
    "                    # delta_3 = sigma_3/sigma_1\n",
    "                    # delta_4 = sigma_4/sigma_1\n",
    "         data = armd)\n",
    "# form ~ v, or ~ v | g, specifying a variance covariate v and, optionally, a grouping factor g for the coefficients.\n",
    "# The variance covariate is ignored in this variance function.\n",
    "\n",
    "# sigma_it = sigma * lambda_it \n",
    "#          = sigma * lambda(delta, TIME_it) \n",
    "#          = sigma * |TIME_it|^delta            \n",
    "weights = varPower(form = ~time)\n",
    "\n",
    "# sigma_it = sigma * lambda_it \n",
    "#          = sigma * lambda(delta, TIME_it) \n",
    "#          = {sigma * |TIME_it|^delta_1    ACTIVE\n",
    "#            {sigma * |TIME_it|^delta_2    PLACEBO\n",
    "weights = varPower(form = ~time|treat.f) #strata=treat.f  \n",
    "\n",
    "fm9.2$modelStruct$varStruct                          # our delta is estimated      \n",
    "\n",
    "\n",
    "###### model 9.4 (REML-based GLS) <delta,mu>-group i.e. lambda(delta,mu,v) ######\n",
    "# delta = scalar, no strata \n",
    "# sigma_it = sigma * lambda_it \n",
    "#          = sigma * lambda(delta, mu_it) \n",
    "#          = sigma * |mu_it|^delta      where mu_it = b_0t + b1 * VISUAL0_i + b_2t * TREAT_i\n",
    "#                                             predicted mean value of VISUAL_it\n",
    "weights = varPower()\n",
    "\n",
    "# delta = 1, no strata \n",
    "# sigma_it = sigma * lambda_it \n",
    "#          = sigma * lambda(mu_it) \n",
    "#          = sigma * mu_it               \n",
    "# NB. the scale parameter can be interpreted as a coefficient of variation, \n",
    "# constant for all timepoints.\n",
    "weights = varPower(fixed = 1)              # <mu>-group\n",
    "\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "intervals(fm9.0, which=\"coef\", level = 1 - alpha)    # 1 - alpha/length(lm9.0$coefficients) if Bonferroni correction\n",
    "intervals(fm9.0, which=\"var-cov\", level = 1 - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#### LMs with fixed effects and correlated residual errors\n",
    "\n",
    "(Vg1 <- Variogram(fm9.2, form = ~ time | subject)) # variable | Strata\n",
    "\n",
    "fm_fit <- gls(lm1.form, weights =                      , \n",
    "                correlation =                     ,\n",
    "                data =                      )\n",
    "intervals(fm12.1, which = \"var-cov\")   # CIs for rho, delta, sigma \n",
    "fm12.2vcov <- getVarCov(fm12.2, individual = \"2\") # Ri for the 2nd subject\n",
    "print(cov2cor(fm12.1vcov), digits = 2, corr = TRUE, stdevs = FALSE)     # C_i\n",
    "\n",
    "\n",
    "\n",
    "#### 1) Compound-Symmetry Correlation Structure - corCompSymm (Chapter 12.3) ####\n",
    "correlation = corCompSymm(form = ~1|subject)\n",
    "\n",
    "#### 2) Heteroscedastic Autoregressive Residual Errors - corAR1 (Chapter 12.4) ####\n",
    "correlation = corAR1(form = ~tp|subject),  # NB: remember that form = ~1 | subject) would lead to a mistake\n",
    "\n",
    "#### 3) General correlation matrix for Residual Errors - corSymm (Chapter 12.5) ####\n",
    "correlation = corSymm(form = ~tp|subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#####   LINEAR MIXED MODELS \n",
    "## 1. 'lme4' with lmer() --> it does not handle heteroscedastic residuals\n",
    "## 2. 'nlme' with lme()  --> it handles heteroscedastic residuals\n",
    "\n",
    "# •with  ́getVarCov (model, type = ’conditional’) ́we extract σ2Ri;\n",
    "getVarCov(fm16.1,                     \n",
    "            type = \"conditional\"      # sigma^2 * R_i \n",
    "            ,individual = \"2\")   \n",
    "# Conditioned to the random effects b_i --> var-cov of the errors are independent and homoscedastic\n",
    "\n",
    "# •with  ́getVarCov (model, type = ’marginal’) ́we extract σ2Vi;\n",
    "#     sigma^2 * V_i for the second subject (type='marginal')\n",
    "getVarCov(fm16.1,                       \n",
    "          type = \"marginal\",      # sigma^2 * V_i: sigma^2*d11 extra-diagonal and sigma^2+d11 on main diagonal\n",
    "          individual = \"2\")\n",
    "\n",
    "# •with  ́VarCorr (model) we extract σ2D (also from the summary).\n",
    "VarCorr(fm16.3)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### homoscedastic residuals  ###   HETEROSCEDASTIC RESIDUALS (VarPower())\n",
    "lm2.form <- formula(visual ~ visual0 + time + treat.f + treat.f:time)\n",
    "fm16.1 <- lme(lm2.form, random =  , weights= , data = armd)\n",
    "#   1. Linear Models with random intercept \n",
    "#Random intercept - Var(VISUALit) = σ2(d11 + 1)\n",
    "random = ~1|subject\n",
    "\n",
    "#   2. Linear Models with random intercept + slope \n",
    "#      2.A general structure of D\n",
    "#General D - Var(VISUALit) = σ2(d11 + 2d12TIMEit + d22TIME2it + 1)\n",
    "random = ~1 + time | subject\n",
    "\n",
    "#      2.B diagonal D\n",
    "#Diagonal D - Var(VISUALit) = σ2(d11 + d22TIME2it + 1)\n",
    "random = list(subject = pdDiag(~time))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Var-Cov matrix of fixed-effects\n",
    "vcovb <- vcov(fm16.1) \n",
    "vcovb\n",
    "# and Correlation of fixed effects\n",
    "corb <- cov2cor(vcovb) \n",
    "nms <- abbreviate(names(fixef(fm16.1)), 5)\n",
    "rownames(corb) <- nms\n",
    "corb\n",
    "\n",
    "# PVRE \n",
    "#------#\n",
    "# i.e. the Percentage of Variance explained by the Random Effect (PVRE).\n",
    "vc <- VarCorr(fm16.1), comp = c(\"Variance\", \"Std.Dev.\")\n",
    "var_b = as.numeric(vc[1,1]) ##### it's must be caluculted each time\n",
    "var_eps = as.numeric(vc[2,1])\n",
    "sd_eps <- summary(fm16.1)$sigma\n",
    "\n",
    "PVRE <- var_b/(var_b+var_eps)\n",
    "PVRE # it is high!\n",
    "\n",
    "\n",
    "# Diagnostic plots \n",
    "#----------------#\n",
    "# 1) Assessing Assumption on the within-group errors\n",
    "plot(fm16.1)  # Pearson and raw residuals are the same now \n",
    "# (no scale is applied since we are dealing with homogeneous variance)\n",
    "par(bg = \"white\")\n",
    "qqnorm(resid(fm16.1)) # normality of the residuals\n",
    "qqline(resid(fm16.1), col='red', lwd=2)\n",
    "\n",
    "# 2) Assessing Assumption on the Random Effects\n",
    "qqnorm(fm16.1, ~ranef(.), main='Normal Q-Q Plot - Random Effects on Intercept')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read a tab-separated .txt file\n",
    "df = pd.read_csv('file.txt', sep='\\t')  # Adjust 'sep' if needed (e.g., ',' for comma, '|' for pipe)\n",
    "\n",
    "Save the DataFrame as a tab-separated .txt file\n",
    "df.to_csv('output.txt', sep='\\t', index=False)  # Set 'index=True' if you want to include the index\n",
    "\n",
    "  df = pd.read_csv('file.txt', sep='\\t', header=None)\n",
    "- Use `index=False` when saving to avoid writing row indices unless required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#### 2. Load Spatial Data ####\n",
    "path = 'Guerry.shp'\n",
    "guerry <- st_read(guerry_path)\n",
    "\n",
    "#### 3. Spatial Weights ####  \n",
    "# - Contiguity Based Weights: `queen_weights()`, `rook_weights()`\n",
    "        # queen_weights(sf_obj, order=1, include_lower_order = False, precision_threshold = 0)        \n",
    "        queen_w <- queen_weights(guerry)\n",
    "        summary(queen_w)\n",
    "\n",
    "        #rook_weights(sf_obj, order=1,include_lower_order=False, precision_threshold = 0)\n",
    "        rook_w <- rook_weights(guerry)\n",
    "        summary(rook_w)\n",
    "\n",
    "# - Distance Based Weights: `distance_weights()`\n",
    "        #distance_weights(geoda_obj, dist_thres, power= 1.0,  is_inverse= False, is_arc= False, is_mile= True)\n",
    "        dist_thres <- min_distthreshold(guerry)\n",
    "        dist_thres\n",
    "        dist_w <- distance_weights(guerry, dist_thres)\n",
    "        summary(dist_w)\n",
    "\n",
    "# - K-Nearest Neighbor Weights: `knn_weights()`\n",
    "        # knn_weights(gda, k, power = 1.0,is_inverse = False, is_arc = False, is_mile = True)\n",
    "        knn6_w <- knn_weights(guerry, 6)\n",
    "        summary(knn6_w)\n",
    "\n",
    "\n",
    "#### 4 Local Indicators of Spatial Association–LISA ####\n",
    "    # - Local Moran: local_moran()\n",
    "    lisa <- local_moran(queen_w,  guerry['Crm_prs'])\n",
    "        # - lisa_clusters(): Get the local cluster indicators returned from LISA computation.\n",
    "        # - lisa_colors(): Get the cluster colors of LISA computation.\n",
    "        # - lisa_labels(): Get the cluster labels of LISA computation.\n",
    "        # - lisa_values(): Get the local spatial autocorrelation values returned from LISA computation.\n",
    "        # - lisa_num_nbrs(): Get the number of neighbors of every observations in LISA computation.\n",
    "        # - lisa_pvalues(): Get the local pseudo-p values of significance returned from LISA computation.\n",
    "\n",
    "    # - Quantile LISA: local_quantilelisa()\n",
    "    # Two input parameters, k and q, need to be specified in the function local_quantilelisa(): \n",
    "    # k is the number of quantiles (k > 2), and the q is the index of selected quantile lisa ranging from 1 to k.\n",
    "    qsa <- local_quantilelisa(queen_w, crm_prp, 5, 5)\n",
    "    # To get the p-values and cluster indicators of the quantile LISA computation:\n",
    "    lisa_pvalues(qsa)\n",
    "    lisa_clusters(qsa)\n",
    "\n",
    "#### 6 Exploratory Spatial Data Analysis ####\n",
    "plot(guerry)\n",
    "\n",
    "# With the LISA results, we can make a local Moran cluster map:\n",
    "lisa_colors <- lisa_colors(lisa)\n",
    "lisa_labels <- lisa_labels(lisa)\n",
    "lisa_clusters <- lisa_clusters(lisa)\n",
    "plot(st_geometry(guerry), \n",
    "     col=sapply(lisa_clusters, function(x){return(lisa_colors[[x+1]])}), \n",
    "     border = \"#333333\", lwd=0.2)\n",
    "title(main = \"Local Moran Map of Crm_prs\")\n",
    "legend('bottomleft', legend = lisa_labels, fill = lisa_colors, border = \"#eeeeee\")\n",
    "\n",
    "# To create a significance map that is associated with the local Moran map, \n",
    "go to file 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "##### Variogram modeling ##### - isotropicity\n",
    "# basic variograms available\n",
    "show.vgms() \n",
    "\n",
    "data=read.table('/Users/amirh_jandaghian/Documents/Polimi/Y 02/Polimi - Git/AS - Applied Statistics (SECCHI PIERCESARE) [2024-25]/Lab/6_Geostatistics/fluoruro.txt')\n",
    "#names(data)[3]='f'\n",
    "attach(data)\n",
    "coordinates(data)=c('X','Y')\n",
    "head(data) # --> correctly imported\n",
    "\n",
    "## weighted least squares fitting a variogram model to the sample variogram\n",
    "## STEPS:\n",
    "## 1) choose a suitable model\n",
    "    # sample (empirical) variogram (binned estimator)\n",
    "    svgm <- variogram(log(col) ~ 1, data, cutoff = 1000, width = 1000/lag) # with all the defaults of the function\n",
    "    plot(svgm, main = 'Sample Variogram', pch=19)\n",
    "\n",
    "    # we can take into account different directions through 'alpha':\n",
    "    plot(variogram(log(zinc) ~ 1, meuse, alpha = c(0, 45, 90, 135)), pch=19)\n",
    "\n",
    "## 2) choose suitable initial values for partial sill, range & nugget\n",
    "    # try reasonable initial values (remember: vgm(sill, model, range, nugget))\n",
    "    v.fit <- fit.variogram(v, vgm(1, \"Sph\", 800, 1))\n",
    "\n",
    "## 3) fit the model using one of the possible fitting criteria\n",
    "    # plot of the final fit\n",
    "    v <- variogram(log(zinc) ~ 1, meuse)\n",
    "    v.fit <- fit.variogram(v, vgm(1, \"Sph\", 800, 1))\n",
    "    plot(v, v.fit, pch = 19) # always do this!\n",
    "\n",
    "# REML in file \n",
    "\n",
    "####          SPATIAL PREDICTION & KRIGING          ####\n",
    "\n",
    "## Prediction at a single new location \n",
    "s0.new = data.frame(x=179180, y=330100) # UTM coordinates \n",
    "coordinates(s0.new) = c('x','y')        # set the coordinates of the dataframe\n",
    "\n",
    "# Create a gstat object setting a spherical (residual) variogram\n",
    "# gstat(g.obj, id, formula, data, model, set,...)\n",
    "g.tr <- gstat(formula = log(zinc) ~ 1, data = meuse, model = v.fit) # v.fit is the variogram model we use\n",
    "\n",
    "## ordinary kriging -  spatially constant mean\n",
    "    # predict(obj, grid, BLUE=FALSE)\n",
    "    s0=as.data.frame(matrix(c(0.3,0.24,D.s0),1,3))\n",
    "    names(s0)=c('X','Y','D')\n",
    "    coordinates(s0)=c('X','Y')\n",
    "\n",
    "    predict(g.tr, s0.new)\n",
    "    # var1.pred is the predicted log(zinc) \n",
    "    # var1.var variance of prediction error (ordinary kriging variance)\n",
    "    # variance > 0 (as expcted)\n",
    "\n",
    "    # this gives the estimate (best linear unbiased estimator) of the mean(trend component) under gls model\n",
    "    predict(g.tr, s0.new, BLUE = TRUE)\n",
    "\n",
    "    # this gives the estimate of the mean (drift component) under gls\n",
    "    predict(g.tr, meuse[1,], BLUE = TRUE) # same mean everywhere (I am under stationarity, same as before)\n",
    "\n",
    "\n",
    "    # prediction over the entire grid\n",
    "    lz.ok <- predict(g.tr, meuse.grid, BLUE = FALSE)\n",
    "    spplot(lz.ok[1], main='Ordinary Kriging - Prediction')\n",
    "    spplot(lz.ok[2], main='Ordinary Kriging - Variance')\n",
    "\n",
    "\n",
    "## universal kriging\n",
    "        # Create a gstat object setting a spherical (residual) variogram\n",
    "        # gstat(g.obj, id, formula, data, model, set,...)\n",
    "        meuse.gstat <- gstat(id = 'zinc', formula = log(zinc) ~ sqrt(dist), # non stationary formula (intercept is automatically inside)\n",
    "                            data = meuse, nmax = 50, model = v.fit, set = list(gls=1))\n",
    "        # Estimate the variogram from GLS residuals:\n",
    "        #?variogram.gstat\n",
    "        v.gls <- variogram(meuse.gstat) # difference wrt before (before we were just giving a formula, now we give the non-stationary object)\n",
    "        plot(v.gls) \n",
    "        # before it was 0.6, now 0.25\n",
    "        v.gls.fit <- fit.variogram(v.gls, vgm(0.25, \"Sph\", 800, 0.8)) # vgm(sill, model, range, nugget)\n",
    "        v.gls.fit\n",
    "        plot(v.gls, v.gls.fit, pch = 19)\n",
    "        # Update gstat object with variogram model\n",
    "        meuse.gstat <- gstat(id = 'zinc', formula = log(zinc) ~ sqrt(dist),\n",
    "                            data = meuse, nmax = 50, model = v.gls.fit, set = list(gls=1))\n",
    "        meuse.gstat\n",
    "\n",
    "    predict(meuse.gstat, s0.new) # you need to give object and new location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# The probabilities of the fair die are (1/6, ..., 1/6) for throwing (\"1\",...,\"6\").\n",
    "# The probabilities of the loaded die are (1/10, ..., 1/10, 1/2) for throwing (\"1\",...,\"5\",\"6\"). \n",
    "# The observer doesn’t know which die is actually taken (the state is hidden), \n",
    "# but the sequence of throws (observations) can be used to infer which die (state) was used.\n",
    "# Can we detect which die is in use at any given time, just by observing the sequence of rolls?\n",
    "# States = {Fair, Loaded}\n",
    "# P(Fair --> Fair) = 0.95\n",
    "# P(Fair --> Loaded) = 0.05\n",
    "# P(Loaded --> Fair) = 0.1\n",
    "# P(Loaded --> Loaded) = 0.9\n",
    "\n",
    "par(bg = \"white\")\n",
    "\n",
    "States = c('Fair', 'Loaded')\n",
    "Symbols = c(1, 2, 3, 4, 5, 6)\n",
    "observations = c(3, 2, 2, 1, 2, 3, 6, 6, 6, 6)\n",
    "transProbs = matrix( c(0.95, 0.1, \n",
    "                       0.05,  0.9), 2)\n",
    "transProbs\n",
    "emissProbs = matrix( c(1/6, 1/10, \n",
    "                       1/6, 1/10,\n",
    "                       1/6, 1/10,\n",
    "                       1/6, 1/10,\n",
    "                       1/6, 1/10,\n",
    "                       1/6, 1/2 ), 2)\n",
    "emissProbs\n",
    "hmm = initHMM(States, Symbols, c(0.5, 0.5), transProbs, emissProbs)\n",
    "hmm\n",
    "viterbi(hmm, observations) # we get the most probable path of hidden states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(file, \"rt\"):\n",
      "\"cannot open file 'data.text': No such file or directory\"\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
      "1. file(file, \"rt\")",
      "2. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = invokeRestart(\"eval_error\", \n .             cnd))\n . }, \"cannot open the connection\", base::quote(file(file, \"rt\")))"
     ]
    }
   ],
   "source": [
    "# System Prompt:\n",
    "You are a skilled statistics student answering an exam in R. Be concise and clear. Focus on solving only what is asked. For each task:\n",
    "- Use clean R code with minimal comments (only where necessary).\n",
    "- Avoid verbose explanations or unnatural phrasing.\n",
    "- Final answers should be highlighted with a short comment (e.g., `# FINAL ANSWER:`).\n",
    "- No over-explaining, just what a capable student would write under time pressure.\n",
    "- write all codes in a block and seperate each question with a comment.\n",
    "\n",
    "Question: \n",
    "\n",
    "Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Question: \n",
    "\n",
    "Data:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
